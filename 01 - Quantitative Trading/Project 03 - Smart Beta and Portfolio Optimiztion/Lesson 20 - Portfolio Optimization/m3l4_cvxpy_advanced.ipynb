{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Portfolio Optimization using cvxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install cvxpy and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colour==0.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.1.5)\n",
      "Collecting cvxpy==1.0.3 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/59/2613468ffbbe3a818934d06b81b9f4877fe054afbf4f99d2f43f398a0b34/cvxpy-1.0.3.tar.gz (880kB)\n",
      "\u001b[K    100% |████████████████████████████████| 880kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from -r requirements.txt (line 3)) (0.10.0)\n",
      "Collecting numpy==1.14.5 (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 2.1MB/s eta 0:00:01  2% |▋                               | 245kB 14.7MB/s eta 0:00:01    8% |██▊                             | 1.0MB 19.3MB/s eta 0:00:01    16% |█████▏                          | 2.0MB 19.8MB/s eta 0:00:01    35% |███████████▏                    | 4.3MB 23.4MB/s eta 0:00:01    44% |██████████████▎                 | 5.4MB 24.9MB/s eta 0:00:01    64% |████████████████████▋           | 7.8MB 23.9MB/s eta 0:00:01    72% |███████████████████████▍        | 8.9MB 9.9MB/s eta 0:00:01    89% |████████████████████████████▊   | 10.9MB 18.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.21.1 (from -r requirements.txt (line 5))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e1/6c514df670b887c77838ab856f57783c07e8760f2e3d5939203a39735e0e/pandas-0.21.1-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.2MB 1.3MB/s eta 0:00:01   12% |███▉                            | 3.2MB 25.3MB/s eta 0:00:01    16% |█████▎                          | 4.3MB 24.7MB/s eta 0:00:01    20% |██████▋                         | 5.4MB 23.5MB/s eta 0:00:01    29% |█████████▍                      | 7.7MB 19.6MB/s eta 0:00:01    59% |███████████████████             | 15.6MB 21.9MB/s eta 0:00:01    63% |████████████████████▍           | 16.7MB 22.3MB/s eta 0:00:01    71% |███████████████████████         | 18.8MB 22.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 14.8MB/s ta 0:00:01    31% |██████████                      | 337kB 19.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.2.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: pytz==2017.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2017.3)\n",
      "Requirement already satisfied: requests==2.18.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.18.4)\n",
      "Collecting scipy==1.0.0 (from -r requirements.txt (line 11))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 50.0MB 701kB/s eta 0:00:01  1% |▌                               | 727kB 20.9MB/s eta 0:00:03    5% |█▊                              | 2.7MB 20.9MB/s eta 0:00:03    7% |██▍                             | 3.8MB 21.5MB/s eta 0:00:03    11% |███▊                            | 5.8MB 21.8MB/s eta 0:00:03    13% |████▎                           | 6.8MB 20.4MB/s eta 0:00:03    21% |███████                         | 10.8MB 21.7MB/s eta 0:00:02    25% |████████▏                       | 12.8MB 21.3MB/s eta 0:00:02    27% |████████▉                       | 13.9MB 22.3MB/s eta 0:00:02    29% |█████████▌                      | 14.9MB 21.2MB/s eta 0:00:02    31% |██████████                      | 15.7MB 17.5MB/s eta 0:00:02    33% |██████████▊                     | 16.8MB 21.0MB/s eta 0:00:02    40% |█████████████                   | 20.2MB 17.9MB/s eta 0:00:02    45% |██████████████▋                 | 22.9MB 17.4MB/s eta 0:00:02    47% |███████████████▏                | 23.7MB 17.3MB/s eta 0:00:02    50% |████████████████▎               | 25.4MB 17.9MB/s eta 0:00:02    52% |████████████████▊               | 26.2MB 18.3MB/s eta 0:00:02    53% |█████████████████▎              | 27.0MB 18.7MB/s eta 0:00:02    55% |█████████████████▉              | 27.9MB 17.3MB/s eta 0:00:02    57% |██████████████████▍             | 28.7MB 16.9MB/s eta 0:00:02    59% |███████████████████             | 29.6MB 19.0MB/s eta 0:00:02    60% |███████████████████▍            | 30.4MB 19.3MB/s eta 0:00:02    62% |████████████████████            | 31.2MB 18.7MB/s eta 0:00:02    64% |████████████████████▌           | 32.1MB 19.6MB/s eta 0:00:01    67% |█████████████████████▊          | 33.9MB 18.1MB/s eta 0:00:01    69% |██████████████████████▎         | 34.9MB 19.2MB/s eta 0:00:01    73% |███████████████████████▌        | 36.8MB 20.1MB/s eta 0:00:01    76% |████████████████████████▋       | 38.5MB 19.2MB/s eta 0:00:01    79% |█████████████████████████▎      | 39.6MB 15.9MB/s eta 0:00:01    80% |█████████████████████████▉      | 40.4MB 17.6MB/s eta 0:00:01    82% |██████████████████████████▍     | 41.2MB 17.9MB/s eta 0:00:01    87% |████████████████████████████    | 43.9MB 16.7MB/s eta 0:00:01    89% |████████████████████████████▊   | 44.9MB 18.5MB/s eta 0:00:01    91% |█████████████████████████████▎  | 45.7MB 19.5MB/s eta 0:00:01    94% |██████████████████████████████▍ | 47.5MB 21.0MB/s eta 0:00:01    96% |███████████████████████████████ | 48.4MB 18.8MB/s eta 0:00:01    98% |███████████████████████████████▌| 49.3MB 18.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (0.19.1)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.11.0)\n",
      "Collecting tqdm==4.19.5 (from -r requirements.txt (line 14))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/3c/341b4fa23cb3abc335207dba057c790f3bb329f6757e1fcd5d347bcf8308/tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 10.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting osqp (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/59/2b80e881be227eecef3f2b257339d182167b55d22a1315ff4303ddcfd42f/osqp-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (208kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 15.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ecos>=2 (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ed/d131ff51f3a8f73420eb1191345eb49f269f23cadef515172e356018cde3/ecos-2.0.7.post1-cp36-cp36m-manylinux1_x86_64.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 12.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scs>=1.1.3 (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/72/33be87cce255d4e9dbbfef547e9fd6ec7ee94d0d0910bb2b13badea3fbbe/scs-2.1.2.tar.gz (3.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.6MB 9.4MB/s eta 0:00:01    38% |████████████▏                   | 1.4MB 21.2MB/s eta 0:00:01    65% |█████████████████████           | 2.3MB 19.1MB/s eta 0:00:01    92% |█████████████████████████████▊  | 3.3MB 16.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/17/5151b6ac2ac9b6276d46c33369ff814b0901872b2a0871771252f02e9192/multiprocess-0.70.9.tar.gz (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 9.0MB/s eta 0:00:01    24% |███████▊                        | 378kB 19.4MB/s eta 0:00:01    91% |█████████████████████████████▍  | 1.4MB 17.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fastcache in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (0.8.2)\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.0.11)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2019.11.28)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from osqp->cvxpy==1.0.3->-r requirements.txt (line 2)) (0.16.0)\n",
      "Collecting dill>=0.3.1 (from multiprocess->cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 15.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.3.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (2.6.0)\n",
      "Building wheels for collected packages: cvxpy, plotly, scs, multiprocess, dill\n",
      "  Running setup.py bdist_wheel for cvxpy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2b/60/0b/0c2596528665e21d698d6f84a3406c52044c7b4ca6ac737cf3\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "  Running setup.py bdist_wheel for scs ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/df/d0/79/37ea880586da03c620ca9ecd5e42adbd86bc6ea84363965c5f\n",
      "  Running setup.py bdist_wheel for multiprocess ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/96/20/ac/9f1d164f7d81787cd6f4401b1d05212807d021fbbbcc301b82\n",
      "  Running setup.py bdist_wheel for dill ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "Successfully built cvxpy plotly scs multiprocess dill\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "\u001b[31mmoviepy 0.2.3.2 has requirement tqdm==4.11.2, but you'll have tqdm 4.19.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, osqp, ecos, scs, dill, multiprocess, cvxpy, pandas, plotly, tqdm\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: scipy 1.2.1\n",
      "    Uninstalling scipy-1.2.1:\n",
      "      Successfully uninstalled scipy-1.2.1\n",
      "  Found existing installation: dill 0.2.7.1\n",
      "    Uninstalling dill-0.2.7.1:\n",
      "      Successfully uninstalled dill-0.2.7.1\n",
      "  Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "  Found existing installation: tqdm 4.11.2\n",
      "    Uninstalling tqdm-4.11.2:\n",
      "      Successfully uninstalled tqdm-4.11.2\n",
      "Successfully installed cvxpy-1.0.3 dill-0.3.1.1 ecos-2.0.7.post1 multiprocess-0.70.9 numpy-1.14.5 osqp-0.6.1 pandas-0.21.1 plotly-2.2.3 scipy-1.0.0 scs-2.1.2 tqdm-4.19.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import quiz_tests_advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's our objective?\n",
    "http://www.cvxpy.org/\n",
    "\n",
    "Let's see how we can use optimization to meet a more advanced objective.  We want to both minimize the portfolio variance and also want to closely track a market cap weighted index.  In other words, we're trying to minimize the distance between the weights of our portfolio and the weights of the index.\n",
    "\n",
    "$Minimize \\left [ \\sigma^2_p + \\lambda \\sqrt{\\sum_{1}^{m}(weight_i - indexWeight_i)^2} \\right  ]$ where $m$ is the number of stocks in the portfolio, and $\\lambda$ is a scaling factor that you can choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "### x vector\n",
    "To create a vector of M variables $\\mathbf{x} = \\begin{bmatrix}\n",
    "x_1 &...& x_M\n",
    "\\end{bmatrix}\n",
    "$\n",
    "we can use `cvx.Variable(m)`\n",
    "\n",
    "### covariance matrix\n",
    "If we have $m$ stock series, the covariance matrix is an $m \\times m$ matrix containing the covariance between each pair of stocks.  We can use [numpy.cov](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html) to get the covariance.  We give it a 2D array in which each row is a stock series, and each column is an observation at the same period of time.\n",
    "\n",
    "The covariance matrix $\\mathbf{P} = \n",
    "\\begin{bmatrix}\n",
    "\\sigma^2_{1,1} & ... & \\sigma^2_{1,m} \\\\ \n",
    "... & ... & ...\\\\\n",
    "\\sigma_{m,1} & ... & \\sigma^2_{m,m}  \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### portfolio variance\n",
    "We can write the portfolio variance $\\sigma^2_p = \\mathbf{x^T} \\mathbf{P} \\mathbf{x}$\n",
    "\n",
    "Recall that the $\\mathbf{x^T} \\mathbf{P} \\mathbf{x}$ is called the quadratic form.\n",
    "We can use the cvxpy function `quad_form(x,P)` to get the quadratic form.\n",
    "\n",
    "### Distance from index weights\n",
    "We want portfolio weights that track the index closely.  So we want to minimize the distance between them.\n",
    "Recall from the Pythagorean theorem that you can get the distance between two points in an x,y plane by adding the square of the x and y distances and taking the square root.  Extending this to any number of dimensions is called the L2 norm.  So: $\\sqrt{\\sum_{1}^{n}(weight_i - indexWeight_i)^2}$  Can also be written as $\\left \\| \\mathbf{x} - \\mathbf{index} \\right \\|_2$.  There's a cvxpy function called [norm()](https://www.cvxpy.org/api_reference/cvxpy.atoms.other_atoms.html#norm)\n",
    "`norm(x, p=2, axis=None)`.  The default is already set to find an L2 norm, so you would pass in one argument, which is the difference between your portfolio weights and the index weights.\n",
    "\n",
    "### objective function\n",
    "We want to minimize both the portfolio variance and the distance of the portfolio weights from the index weights.\n",
    "We also want to choose a `scale` constant, which is $\\lambda$ in the expression. This lets us choose how much priority we give to minimizing the difference from the index, relative to minimizing the variance of the portfolio.  If you choose a higher value for `scale` ($\\lambda$), do you think this gives more priority to minimizing the difference, or minimizing the variance?\n",
    "\n",
    "We can find the objective function using cvxpy `objective = cvx.Minimize()`.  Can you guess what to pass into this function?\n",
    "\n",
    "### constraints\n",
    "We can also define our constraints in a list.  For example, you'd want the weights to sum to one. So $\\sum_{1}^{n}x = 1$.  You may also need to go long only, which means no shorting, so no negative weights.  So $x_i >0 $ for all $i$. you could save a variable as `[x >= 0, sum(x) == 1]`, where x was created using `cvx.Variable()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization\n",
    "So now that we have our objective function and constraints, we can solve for the values of $\\mathbf{x}$.\n",
    "cvxpy has the constructor `Problem(objective, constraints)`, which returns a `Problem` object.\n",
    "\n",
    "The `Problem` object has a function solve(), which returns the minimum of the solution.  In this case, this is the minimum variance of the portfolio.\n",
    "\n",
    "It also updates the vector $\\mathbf{x}$.\n",
    "\n",
    "We can check out the values of $x_A$ and $x_B$ that gave the minimum portfolio variance by using `x.value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong value for optimize_portfolio.\n\nINPUT returns:\n[[-0.18576252 -0.01581422  0.00105172 -0.12986104  0.33714221  0.24987429\n   0.13473871 -0.49963602 -0.12688536 -0.10273357  0.60654501  0.12984134\n  -0.32542494  0.17099126  0.28204022 -0.36595609  0.00647034 -0.09076468\n  -0.05990462  0.38059237  0.31038744  0.07550292 -0.37525315  0.25935232\n   0.36934776  0.14081369 -0.0241702  -0.33745597  0.4279998  -0.23600535\n  -0.43319191 -0.23422814 -0.05238667 -0.14456376 -0.00268175 -0.23770175\n  -0.53178952  0.02007463  0.77934214  0.54782649 -0.22074427  0.55586226\n  -0.28699057  0.14837687 -0.09203855 -0.11061514 -0.27648705  0.23964429\n   0.73277546 -0.05561099 -0.07504271 -0.12607693  0.46138813  0.346017\n  -0.08422098 -0.17576238  0.20448621  0.3472651  -0.159198    0.13811693\n   0.24694112 -0.12167204  0.5954018   0.29503768  0.36328686  0.09397652\n  -0.41613483  0.53448069  0.38932524 -0.17415213  0.05940382  0.21088978\n   0.2242418  -0.20895893  0.5780443  -0.02024809 -0.3233942   0.01316555\n   0.28874712  0.5616503   0.11194306 -0.19984869 -0.23247065  0.18191204\n   0.07399281  0.22402454 -0.13243149 -0.26671085 -0.31988752  0.30275568\n  -0.48110545  0.11643497 -0.24864809  0.40617901 -0.0880447   0.19396697\n  -0.46771005  0.52396094  0.08387816 -0.5338876   0.26433297  0.28348667\n  -0.62951667  0.24753278  0.21260479  0.26526696  0.08493333 -0.19451498\n   0.21393836 -0.1209355   0.37758689  0.34423284 -0.34133099  0.31952152\n  -0.00208691 -0.03845675  0.52338735  0.11551241  0.11306455 -0.11379474\n   0.63354693 -0.40504401  0.36726798 -0.39650067 -0.37670915 -0.0421782\n   0.18225316  0.26336803 -0.0413825   0.24636226  0.35989326  0.24285888\n   0.4394538  -0.23959426  0.4570156   0.03778728  0.24876682 -0.14361911\n  -0.08496095 -0.46293632 -0.15883169 -0.41046624  0.00656     0.41510511\n  -0.18445483 -0.05584148 -0.58335713 -0.01412016 -0.07318603  0.10052238\n   0.13474026  0.16061219 -0.12609863 -0.3784463  -0.27857833 -0.14841302\n   0.19764921  0.07551291 -0.1122142   0.44847839 -0.92586707  0.2687803\n   0.00667772  0.08212403 -0.3073165  -0.17470966  0.00574868  0.06313716\n   0.2376201  -0.21977247  0.03197334 -0.18894091 -0.26623177  0.71908865\n   0.47913364  0.19926017  0.2047519  -0.45323263 -0.03607609 -0.09524947\n   0.46275963  0.30581421  0.20728419  0.44303284  0.33161731 -0.04376111\n   0.51048107 -0.14135958 -0.13408556  0.00845561  0.1032144  -0.42330374\n  -0.41031251 -0.11108435  0.05353534  0.31163759 -0.04046894  0.4989882\n   0.13973409  0.30201146 -0.14010001 -0.23181464 -0.19242583  0.08396978\n  -0.54003899  0.51762895 -0.10295221  0.07563546 -0.11695563 -0.17742338\n   0.16659634 -0.02858997 -0.15091102  0.43561608  0.11091588  0.16115567\n   0.0677525  -0.23628348 -0.16075506  0.04635633 -0.18785925  0.19754916\n   0.20058404  0.20533252  0.13571489  0.37151456 -0.05390771 -0.26035601\n  -0.08415663  0.13089477  0.04907823 -0.30258588  0.37555614  0.04506388\n   0.29840511  0.12614824 -0.12638489 -0.09159116 -0.14726592 -0.13652668\n   0.32530333  0.29028171  0.01204708 -0.17488307  0.28849981  0.01954659\n   0.14126614 -0.16828736  0.2659895  -0.54081368  0.61602667 -0.24322261]\n [-0.18576083 -0.01581454  0.00105272 -0.12986177  0.33714208  0.24987453\n   0.13473976 -0.49963691 -0.12688557 -0.10273361  0.60654372  0.12984214\n  -0.3254242   0.1709913   0.28203922 -0.3659561   0.00647123 -0.0907655\n  -0.05990501  0.38059266  0.31038676  0.0755037  -0.37525343  0.25935251\n   0.36934777  0.14081398 -0.02417104 -0.33745591  0.42799954 -0.23600669\n  -0.43319011 -0.23422805 -0.052387   -0.1445649  -0.00268269 -0.23770375\n  -0.53179054  0.02007593  0.77934151  0.54782524 -0.22074414  0.55586239\n  -0.2869898   0.14837664 -0.09203824 -0.11061465 -0.27648874  0.23964349\n   0.73277588 -0.0556106  -0.07504209 -0.1260764   0.46138654  0.34601641\n  -0.08422077 -0.17576283  0.20448658  0.34726411 -0.15919839  0.1381173\n   0.24694131 -0.12167256  0.59540211  0.29503839  0.36328654  0.09397575\n  -0.41613619  0.53448044  0.38932414 -0.17415237  0.05940412  0.21088964\n   0.2242419  -0.20895969  0.57804356 -0.02024708 -0.32339338  0.01316587\n   0.28874883  0.5616494   0.11194319 -0.19984987 -0.23247121  0.1819129\n   0.07399235  0.22402372 -0.13243147 -0.26671186 -0.31988633  0.30275547\n  -0.48110354  0.11643535 -0.24864967  0.40617748 -0.08804536  0.19396863\n  -0.46770926  0.52396024  0.08387804 -0.53388764  0.26433277  0.2834864\n  -0.62951745  0.24753229  0.2126058   0.26526625  0.08493364 -0.19451452\n   0.21393851 -0.12093699  0.37758685  0.3442343  -0.34133151  0.31952198\n  -0.00208531 -0.03845702  0.5233878   0.11551111  0.11306442 -0.11379399\n   0.63354557 -0.40504304  0.36726772 -0.39650072 -0.37670845 -0.04217653\n   0.18225221  0.26336689 -0.04138182  0.24636202  0.35989392  0.24285821\n   0.43945479 -0.2395961   0.45701372  0.03778724  0.24876746 -0.14361917\n  -0.08496077 -0.46293636 -0.15883168 -0.41046478  0.00656059  0.41510546\n  -0.18445433 -0.05584264 -0.5833577  -0.01412019 -0.07318698  0.10052158\n   0.13474019  0.16061306 -0.12609884 -0.37844569 -0.27857808 -0.14841316\n   0.19764857  0.07551306 -0.11221384  0.44847767 -0.92586656  0.26877971\n   0.00667814  0.08212278 -0.30731673 -0.17470948  0.00574976  0.06313858\n   0.23762059 -0.21977277  0.03197354 -0.1889418  -0.26623169  0.71908967\n   0.47913326  0.1992591   0.20475056 -0.45323382 -0.03607611 -0.09525039\n   0.4627594   0.30581321  0.20728496  0.44303278  0.33161826 -0.04376082\n   0.51048179 -0.14136129 -0.13408411  0.00845558  0.10321469 -0.42330402\n  -0.4103122  -0.1110845   0.05353527  0.31163885 -0.04046892  0.49898745\n   0.13973337  0.30201028 -0.14010036 -0.23181456 -0.19242715  0.08397089\n  -0.5400392   0.51762923 -0.10295161  0.07563621 -0.11695657 -0.1774221\n   0.16659541 -0.02859058 -0.15091036  0.4356164   0.11091569  0.16115568\n   0.067752   -0.23628252 -0.16075495  0.04635637 -0.18785823  0.19754914\n   0.20058494  0.2053334   0.13571374  0.37151627 -0.05390772 -0.26035702\n  -0.08415804  0.13089575  0.04907681 -0.30258692  0.37555745  0.0450643\n   0.29840454  0.12614873 -0.12638514 -0.09159238 -0.14726462 -0.13652571\n   0.3253033   0.29028023  0.01204827 -0.17488232  0.28850094  0.01954614\n   0.14126532 -0.1682864   0.26598902 -0.54081312  0.61602675 -0.24322206]\n [-0.18576192 -0.01581421  0.00105199 -0.12986058  0.33714114  0.24987343\n   0.13473943 -0.4996374  -0.12688624 -0.10273423  0.60654444  0.12984263\n  -0.32542547  0.17099009  0.28203947 -0.36595724  0.00647003 -0.090765\n  -0.05990647  0.38059245  0.31038833  0.075504   -0.37525478  0.25935288\n   0.36934702  0.14081385 -0.02417097 -0.33745542  0.42799845 -0.23600709\n  -0.43319128 -0.23422901 -0.0523876  -0.14456369 -0.00268258 -0.23770275\n  -0.53179126  0.02007577  0.77934086  0.54782605 -0.22074386  0.55586405\n  -0.28698985  0.14837817 -0.09203839 -0.11061492 -0.27648817  0.23964407\n   0.73277496 -0.05561057 -0.0750427  -0.12607731  0.46138694  0.34601678\n  -0.08422074 -0.17576328  0.20448558  0.34726587 -0.15919814  0.13811721\n   0.24694223 -0.12167351  0.59540074  0.29503854  0.36328656  0.09397576\n  -0.41613502  0.53447962  0.38932506 -0.17415346  0.05940441  0.21088895\n   0.224242   -0.20895878  0.57804334 -0.02024667 -0.3233936   0.01316525\n   0.28874892  0.56165037  0.11194383 -0.19984942 -0.23247153  0.18191236\n   0.07399266  0.22402412 -0.13243088 -0.2667108  -0.3198864   0.30275417\n  -0.48110547  0.11643595 -0.24864972  0.40617896 -0.0880448   0.19396826\n  -0.46770892  0.5239598   0.08387779 -0.53388693  0.26433305  0.28348761\n  -0.62951783  0.24753133  0.21260466  0.26526664  0.08493463 -0.19451444\n   0.2139394  -0.12093651  0.37758664  0.34423368 -0.34133183  0.31952147\n  -0.00208698 -0.03845753  0.52338783  0.11551073  0.11306518 -0.11379423\n   0.63354615 -0.40504392  0.36726728 -0.39650078 -0.37670904 -0.0421777\n   0.18225259  0.26336777 -0.04138129  0.24636352  0.35989248  0.24285798\n   0.43945362 -0.23959521  0.45701558  0.03778691  0.24876845 -0.14361882\n  -0.0849607  -0.46293639 -0.15883027 -0.41046602  0.00656157  0.4151054\n  -0.18445422 -0.05584202 -0.58335764 -0.01411934 -0.07318724  0.10052179\n   0.13473931  0.16061174 -0.12609906 -0.37844744 -0.27857866 -0.14841314\n   0.1976492   0.07551278 -0.11221438  0.44847844 -0.92586713  0.26877938\n   0.00667786  0.08212426 -0.30731633 -0.17470936  0.00574844  0.0631367\n   0.23762017 -0.21977244  0.03197271 -0.18894014 -0.26623206  0.71908885\n   0.47913409  0.19926051  0.20475075 -0.45323283 -0.03607596 -0.09524979\n   0.46275909  0.3058142   0.20728456  0.44303314  0.3316171  -0.04376036\n   0.51048175 -0.14136037 -0.13408452  0.00845561  0.10321348 -0.42330377\n  -0.41031163 -0.11108527  0.05353486  0.31163831 -0.04046944  0.49898795\n   0.1397339   0.30201006 -0.14009875 -0.23181309 -0.19242695  0.08397057\n  -0.54003874  0.51762908 -0.10295161  0.07563624 -0.11695701 -0.17742186\n   0.1665955  -0.02858913 -0.15091125  0.43561485  0.11091635  0.16115469\n   0.0677517  -0.23628398 -0.16075535  0.04635533 -0.18785918  0.19754815\n   0.2005854   0.20533396  0.13571453  0.3715151  -0.05390819 -0.26035666\n  -0.08415672  0.13089476  0.04907834 -0.3025862   0.37555615  0.04506481\n   0.29840546  0.12614935 -0.12638388 -0.09159096 -0.14726558 -0.13652588\n   0.32530342  0.29028102  0.01204825 -0.17488284  0.28850068  0.01954597\n   0.14126673 -0.16828628  0.26598975 -0.54081411  0.61602666 -0.24322135]]\n\nINPUT index_weights:\n[0.9  0.15 0.05]\n\nINPUT scale:\n1e-05\n\nOUTPUT x_values:\n[0.8666681  0.11666503 0.01666687]\n\nEXPECTED OUTPUT FOR x_values:\n[0.8673451  0.11651033 0.01614457]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-86ea80fb05e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mquiz_tests_advanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_optimize_portfolio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_portfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/workspace/tests.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproject_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tests Passed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/quiz_tests_advanced.py\u001b[0m in \u001b[0;36mtest_optimize_portfolio\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     43\u001b[0m         ])\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0massert_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_correct_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/workspace/tests.py\u001b[0m in \u001b[0;36massert_output\u001b[0;34m(fn, fn_inputs, fn_expected_outputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mout_is_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_is_close\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mout_is_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Wrong value for optimize_portfolio.\n\nINPUT returns:\n[[-0.18576252 -0.01581422  0.00105172 -0.12986104  0.33714221  0.24987429\n   0.13473871 -0.49963602 -0.12688536 -0.10273357  0.60654501  0.12984134\n  -0.32542494  0.17099126  0.28204022 -0.36595609  0.00647034 -0.09076468\n  -0.05990462  0.38059237  0.31038744  0.07550292 -0.37525315  0.25935232\n   0.36934776  0.14081369 -0.0241702  -0.33745597  0.4279998  -0.23600535\n  -0.43319191 -0.23422814 -0.05238667 -0.14456376 -0.00268175 -0.23770175\n  -0.53178952  0.02007463  0.77934214  0.54782649 -0.22074427  0.55586226\n  -0.28699057  0.14837687 -0.09203855 -0.11061514 -0.27648705  0.23964429\n   0.73277546 -0.05561099 -0.07504271 -0.12607693  0.46138813  0.346017\n  -0.08422098 -0.17576238  0.20448621  0.3472651  -0.159198    0.13811693\n   0.24694112 -0.12167204  0.5954018   0.29503768  0.36328686  0.09397652\n  -0.41613483  0.53448069  0.38932524 -0.17415213  0.05940382  0.21088978\n   0.2242418  -0.20895893  0.5780443  -0.02024809 -0.3233942   0.01316555\n   0.28874712  0.5616503   0.11194306 -0.19984869 -0.23247065  0.18191204\n   0.07399281  0.22402454 -0.13243149 -0.26671085 -0.31988752  0.30275568\n  -0.48110545  0.11643497 -0.24864809  0.40617901 -0.0880447   0.19396697\n  -0.46771005  0.52396094  0.08387816 -0.5338876   0.26433297  0.28348667\n  -0.62951667  0.24753278  0.21260479  0.26526696  0.08493333 -0.19451498\n   0.21393836 -0.1209355   0.37758689  0.34423284 -0.34133099  0.31952152\n  -0.00208691 -0.03845675  0.52338735  0.11551241  0.11306455 -0.11379474\n   0.63354693 -0.40504401  0.36726798 -0.39650067 -0.37670915 -0.0421782\n   0.18225316  0.26336803 -0.0413825   0.24636226  0.35989326  0.24285888\n   0.4394538  -0.23959426  0.4570156   0.03778728  0.24876682 -0.14361911\n  -0.08496095 -0.46293632 -0.15883169 -0.41046624  0.00656     0.41510511\n  -0.18445483 -0.05584148 -0.58335713 -0.01412016 -0.07318603  0.10052238\n   0.13474026  0.16061219 -0.12609863 -0.3784463  -0.27857833 -0.14841302\n   0.19764921  0.07551291 -0.1122142   0.44847839 -0.92586707  0.2687803\n   0.00667772  0.08212403 -0.3073165  -0.17470966  0.00574868  0.06313716\n   0.2376201  -0.21977247  0.03197334 -0.18894091 -0.26623177  0.71908865\n   0.47913364  0.19926017  0.2047519  -0.45323263 -0.03607609 -0.09524947\n   0.46275963  0.30581421  0.20728419  0.44303284  0.33161731 -0.04376111\n   0.51048107 -0.14135958 -0.13408556  0.00845561  0.1032144  -0.42330374\n  -0.41031251 -0.11108435  0.05353534  0.31163759 -0.04046894  0.4989882\n   0.13973409  0.30201146 -0.14010001 -0.23181464 -0.19242583  0.08396978\n  -0.54003899  0.51762895 -0.10295221  0.07563546 -0.11695563 -0.17742338\n   0.16659634 -0.02858997 -0.15091102  0.43561608  0.11091588  0.16115567\n   0.0677525  -0.23628348 -0.16075506  0.04635633 -0.18785925  0.19754916\n   0.20058404  0.20533252  0.13571489  0.37151456 -0.05390771 -0.26035601\n  -0.08415663  0.13089477  0.04907823 -0.30258588  0.37555614  0.04506388\n   0.29840511  0.12614824 -0.12638489 -0.09159116 -0.14726592 -0.13652668\n   0.32530333  0.29028171  0.01204708 -0.17488307  0.28849981  0.01954659\n   0.14126614 -0.16828736  0.2659895  -0.54081368  0.61602667 -0.24322261]\n [-0.18576083 -0.01581454  0.00105272 -0.12986177  0.33714208  0.24987453\n   0.13473976 -0.49963691 -0.12688557 -0.10273361  0.60654372  0.12984214\n  -0.3254242   0.1709913   0.28203922 -0.3659561   0.00647123 -0.0907655\n  -0.05990501  0.38059266  0.31038676  0.0755037  -0.37525343  0.25935251\n   0.36934777  0.14081398 -0.02417104 -0.33745591  0.42799954 -0.23600669\n  -0.43319011 -0.23422805 -0.052387   -0.1445649  -0.00268269 -0.23770375\n  -0.53179054  0.02007593  0.77934151  0.54782524 -0.22074414  0.55586239\n  -0.2869898   0.14837664 -0.09203824 -0.11061465 -0.27648874  0.23964349\n   0.73277588 -0.0556106  -0.07504209 -0.1260764   0.46138654  0.34601641\n  -0.08422077 -0.17576283  0.20448658  0.34726411 -0.15919839  0.1381173\n   0.24694131 -0.12167256  0.59540211  0.29503839  0.36328654  0.09397575\n  -0.41613619  0.53448044  0.38932414 -0.17415237  0.05940412  0.21088964\n   0.2242419  -0.20895969  0.57804356 -0.02024708 -0.32339338  0.01316587\n   0.28874883  0.5616494   0.11194319 -0.19984987 -0.23247121  0.1819129\n   0.07399235  0.22402372 -0.13243147 -0.26671186 -0.31988633  0.30275547\n  -0.48110354  0.11643535 -0.24864967  0.40617748 -0.08804536  0.19396863\n  -0.46770926  0.52396024  0.08387804 -0.53388764  0.26433277  0.2834864\n  -0.62951745  0.24753229  0.2126058   0.26526625  0.08493364 -0.19451452\n   0.21393851 -0.12093699  0.37758685  0.3442343  -0.34133151  0.31952198\n  -0.00208531 -0.03845702  0.5233878   0.11551111  0.11306442 -0.11379399\n   0.63354557 -0.40504304  0.36726772 -0.39650072 -0.37670845 -0.04217653\n   0.18225221  0.26336689 -0.04138182  0.24636202  0.35989392  0.24285821\n   0.43945479 -0.2395961   0.45701372  0.03778724  0.24876746 -0.14361917\n  -0.08496077 -0.46293636 -0.15883168 -0.41046478  0.00656059  0.41510546\n  -0.18445433 -0.05584264 -0.5833577  -0.01412019 -0.07318698  0.10052158\n   0.13474019  0.16061306 -0.12609884 -0.37844569 -0.27857808 -0.14841316\n   0.19764857  0.07551306 -0.11221384  0.44847767 -0.92586656  0.26877971\n   0.00667814  0.08212278 -0.30731673 -0.17470948  0.00574976  0.06313858\n   0.23762059 -0.21977277  0.03197354 -0.1889418  -0.26623169  0.71908967\n   0.47913326  0.1992591   0.20475056 -0.45323382 -0.03607611 -0.09525039\n   0.4627594   0.30581321  0.20728496  0.44303278  0.33161826 -0.04376082\n   0.51048179 -0.14136129 -0.13408411  0.00845558  0.10321469 -0.42330402\n  -0.4103122  -0.1110845   0.05353527  0.31163885 -0.04046892  0.49898745\n   0.13973337  0.30201028 -0.14010036 -0.23181456 -0.19242715  0.08397089\n  -0.5400392   0.51762923 -0.10295161  0.07563621 -0.11695657 -0.1774221\n   0.16659541 -0.02859058 -0.15091036  0.4356164   0.11091569  0.16115568\n   0.067752   -0.23628252 -0.16075495  0.04635637 -0.18785823  0.19754914\n   0.20058494  0.2053334   0.13571374  0.37151627 -0.05390772 -0.26035702\n  -0.08415804  0.13089575  0.04907681 -0.30258692  0.37555745  0.0450643\n   0.29840454  0.12614873 -0.12638514 -0.09159238 -0.14726462 -0.13652571\n   0.3253033   0.29028023  0.01204827 -0.17488232  0.28850094  0.01954614\n   0.14126532 -0.1682864   0.26598902 -0.54081312  0.61602675 -0.24322206]\n [-0.18576192 -0.01581421  0.00105199 -0.12986058  0.33714114  0.24987343\n   0.13473943 -0.4996374  -0.12688624 -0.10273423  0.60654444  0.12984263\n  -0.32542547  0.17099009  0.28203947 -0.36595724  0.00647003 -0.090765\n  -0.05990647  0.38059245  0.31038833  0.075504   -0.37525478  0.25935288\n   0.36934702  0.14081385 -0.02417097 -0.33745542  0.42799845 -0.23600709\n  -0.43319128 -0.23422901 -0.0523876  -0.14456369 -0.00268258 -0.23770275\n  -0.53179126  0.02007577  0.77934086  0.54782605 -0.22074386  0.55586405\n  -0.28698985  0.14837817 -0.09203839 -0.11061492 -0.27648817  0.23964407\n   0.73277496 -0.05561057 -0.0750427  -0.12607731  0.46138694  0.34601678\n  -0.08422074 -0.17576328  0.20448558  0.34726587 -0.15919814  0.13811721\n   0.24694223 -0.12167351  0.59540074  0.29503854  0.36328656  0.09397576\n  -0.41613502  0.53447962  0.38932506 -0.17415346  0.05940441  0.21088895\n   0.224242   -0.20895878  0.57804334 -0.02024667 -0.3233936   0.01316525\n   0.28874892  0.56165037  0.11194383 -0.19984942 -0.23247153  0.18191236\n   0.07399266  0.22402412 -0.13243088 -0.2667108  -0.3198864   0.30275417\n  -0.48110547  0.11643595 -0.24864972  0.40617896 -0.0880448   0.19396826\n  -0.46770892  0.5239598   0.08387779 -0.53388693  0.26433305  0.28348761\n  -0.62951783  0.24753133  0.21260466  0.26526664  0.08493463 -0.19451444\n   0.2139394  -0.12093651  0.37758664  0.34423368 -0.34133183  0.31952147\n  -0.00208698 -0.03845753  0.52338783  0.11551073  0.11306518 -0.11379423\n   0.63354615 -0.40504392  0.36726728 -0.39650078 -0.37670904 -0.0421777\n   0.18225259  0.26336777 -0.04138129  0.24636352  0.35989248  0.24285798\n   0.43945362 -0.23959521  0.45701558  0.03778691  0.24876845 -0.14361882\n  -0.0849607  -0.46293639 -0.15883027 -0.41046602  0.00656157  0.4151054\n  -0.18445422 -0.05584202 -0.58335764 -0.01411934 -0.07318724  0.10052179\n   0.13473931  0.16061174 -0.12609906 -0.37844744 -0.27857866 -0.14841314\n   0.1976492   0.07551278 -0.11221438  0.44847844 -0.92586713  0.26877938\n   0.00667786  0.08212426 -0.30731633 -0.17470936  0.00574844  0.0631367\n   0.23762017 -0.21977244  0.03197271 -0.18894014 -0.26623206  0.71908885\n   0.47913409  0.19926051  0.20475075 -0.45323283 -0.03607596 -0.09524979\n   0.46275909  0.3058142   0.20728456  0.44303314  0.3316171  -0.04376036\n   0.51048175 -0.14136037 -0.13408452  0.00845561  0.10321348 -0.42330377\n  -0.41031163 -0.11108527  0.05353486  0.31163831 -0.04046944  0.49898795\n   0.1397339   0.30201006 -0.14009875 -0.23181309 -0.19242695  0.08397057\n  -0.54003874  0.51762908 -0.10295161  0.07563624 -0.11695701 -0.17742186\n   0.1665955  -0.02858913 -0.15091125  0.43561485  0.11091635  0.16115469\n   0.0677517  -0.23628398 -0.16075535  0.04635533 -0.18785918  0.19754815\n   0.2005854   0.20533396  0.13571453  0.3715151  -0.05390819 -0.26035666\n  -0.08415672  0.13089476  0.04907834 -0.3025862   0.37555615  0.04506481\n   0.29840546  0.12614935 -0.12638388 -0.09159096 -0.14726558 -0.13652588\n   0.32530342  0.29028102  0.01204825 -0.17488284  0.28850068  0.01954597\n   0.14126673 -0.16828628  0.26598975 -0.54081411  0.61602666 -0.24322135]]\n\nINPUT index_weights:\n[0.9  0.15 0.05]\n\nINPUT scale:\n1e-05\n\nOUTPUT x_values:\n[0.8666681  0.11666503 0.01666687]\n\nEXPECTED OUTPUT FOR x_values:\n[0.8673451  0.11651033 0.01614457]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "\n",
    "def optimize_portfolio(returns, index_weights, scale=.00001):\n",
    "    \"\"\"\n",
    "    Create a function that takes the return series of a set of stocks, the index weights,\n",
    "    and scaling factor. The function will minimize a combination of the portfolio variance\n",
    "    and the distance of its weights from the index weights.  \n",
    "    The optimization will be constrained to be long only, and the weights should sum to one.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : numpy.ndarray\n",
    "        2D array containing stock return series in each row.\n",
    "        \n",
    "    index_weights : numpy.ndarray\n",
    "        1D numpy array containing weights of the index.\n",
    "        \n",
    "    scale : float\n",
    "        The scaling factor applied to the distance between portfolio and index weights\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray\n",
    "        A numpy ndarray containing the weights of the stocks in the optimized portfolio\n",
    "    \"\"\"\n",
    "    # TODO: Use cvxpy to determine the weights on the assets\n",
    "    # that minimizes the combination of portfolio variance and distance from index weights\n",
    "    \n",
    "    # number of stocks m is number of rows of returns, and also number of index weights\n",
    "    m = len(returns)\n",
    "    \n",
    "    #covariance matrix of returns\n",
    "    cov = np.cov(returns) \n",
    "    \n",
    "    # x variables (to be found with optimization)\n",
    "    x = cvx.Variable(m)\n",
    "    \n",
    "    #portfolio variance, in quadratic form\n",
    "    portfolio_variance = cvx.quad_form(x,cov)\n",
    "    \n",
    "    # euclidean distance (L2 norm) between portfolio and index weights\n",
    "    distance_to_index = x - index_weights\n",
    "    \n",
    "    #objective function\n",
    "    objective = cvx.Minimize(portfolio_variance + scale+cvx.norm(distance_to_index, p=2, axis=None))\n",
    "    \n",
    "    #constraints\n",
    "    constraints = [x >= 0, sum(x) == 1]\n",
    "\n",
    "    #use cvxpy to solve the objective\n",
    "    problem = cvx.Problem(objective, constraints)\n",
    "    min_value = problem.solve()\n",
    "    \n",
    "    #retrieve the weights of the optimized portfolio\n",
    "    x_values = x.value\n",
    "    \n",
    "    return x_values\n",
    "\n",
    "quiz_tests_advanced.test_optimize_portfolio(optimize_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimized weights are [0.8666681  0.11666503 0.01666687], which sum to 1.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test with a 3 simulated stock return series\"\"\"\n",
    "days_per_year = 252\n",
    "years = 3\n",
    "total_days = days_per_year * years\n",
    "\n",
    "return_market = np.random.normal(loc=0.05, scale=0.3, size=days_per_year)\n",
    "return_1 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "return_2 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "return_3 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "returns = np.array([return_1, return_2, return_3])\n",
    "\n",
    "\"\"\"simulate index weights\"\"\"\n",
    "index_weights = np.array([0.9,0.15,0.05])\n",
    "\n",
    "\"\"\"try out your optimization function\"\"\"\n",
    "x_values = optimize_portfolio(returns, index_weights, scale=.00001)\n",
    "\n",
    "print(f\"The optimized weights are {x_values}, which sum to {sum(x_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're feeling stuck, you can check out the solution [here](m3l4_cvxpy_advanced_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
